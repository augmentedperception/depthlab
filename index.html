<!DOCTYPE html><html lang=en> <head><title>DepthLab: Real-Time 3D Interaction With Depth Maps for Mobile Augmented Reality</title><meta charset=UTF-8><meta name=viewport content="width=device-width,minimum-scale=1.0"><meta name=description content="DepthLab: Real-Time 3D Interaction With Depth Maps for Mobile Augmented Reality is a UIST 2020 Technical Paper."><meta name=keywords content="deep view, light field video, augmented perception, google, UIST"><meta name=author content="Augmented Perception, Google"><meta name=robots content=all><link rel=apple-touch-icon sizes=180x180 href=assets/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=assets/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=assets/favicons/favicon-16x16.png><link rel=manifest href=assets/site.webmanifest><link rel=mask-icon href=assets/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content=#da532c><meta name=theme-color content=#ffffff><link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700;900&family=Open+Sans:wght@300;400;600;700;800&family=Roboto:wght@400;500;700;900&display=swap" rel=stylesheet><link rel=stylesheet href=assets/css/style.css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-56800740-3"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "UA-56800740-3");
    </script></head> <body> <canvas id=global-canvas></canvas> <div class=container> <div class=header> <div class=title> <h1> DepthLab: Real-Time 3D Interaction With Depth Maps <br> for Mobile Augmented Reality </h1> <div class=title-line><hr></div> </div> <div class=subheading> <h2>ACM UIST 2020</h2> <p class=subheading-link> <a href=assets/Du_DepthLab-Real-Time3DInteractionWithDepthMapsForMobileAugmentedReality_UIST2020.pdf>Download PDF (6 MB)</a> or <a href=assets/Du_DepthLab-Real-Time3DInteractionWithDepthMapsForMobileAugmentedReality_UIST2020_lowres.pdf>Low-Res PDF (4 MB)</a> </p> </div> <div class=authors> <h4> <p style=text-align:center> <span class=no-wrap><a href=https://duruofei.com target=_blank>Ruofei Du</a></span>, <span class=no-wrap><a href=https://research.google/people/105965 target=_blank>Eric Turner</a>,</span> <span class=no-wrap><a href=https://linkedin.com/in/maxdzitsiuk target=_blank> Maksym Dzitsiuk</a>,</span> <span class=no-wrap><a href=http://lucaprasso.com target=_blank>Luca Prasso</a></span>, <span class=no-wrap><a href=https://linkedin.com/in/duarteivo target=_blank>Ivo Duarte</a>,</span> <span class=no-wrap><a href="https://scholar.google.com/citations?user=XrBZgTgAAAAJ" target=_blank>Jason Dourgarian</a>,</span> <span class=no-wrap><a href=https://linkedin.com/in/roimatola target=_blank>Joao Afonso</a>,</span> <span class=no-wrap><a href=https://linkedin.com/in/josepascoal target=_blank>Jose Pascoal</a>,</span> <span class=no-wrap><a href=https://www.linkedin.com/in/josh-gladstone-9238a2142/ target=_blank>Josh Gladstone</a>,</span> <span class=no-wrap><a href=https://linkedin.com/in/nunocruces target=_blank>Nuno Cruces</a>,</span> <span class=no-wrap><a href="https://scholar.google.com/citations?user=hkCVqYkAAAAJ" target=_blank>Shahram Izadi</a>,</span> <span class=no-wrap><a href="https://scholar.google.com/citations?user=BtxiLV4AAAAJ" target=_blank>Adarsh Kowdle</a>,</span> <span class=no-wrap><a href=https://sites.google.com/site/ktsotsos target=_blank>Konstantine Tsotsos</a>,</span> <span class=no-wrap><a href=http://davidkim.de target=_blank>David Kim</a></span> </p> </h4> </div> <div class=organization> <h3>Google LLC</h3> </div> </div> <div class=content> <div class="section video-container"> <iframe width=560 height=315 src=https://www.youtube.com/embed/wfVmq7d_v-I frameborder=0 allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </div> <div class=paper-thumbnails> <div class=page> <a href=assets/Du_DepthLab-Real-Time3DInteractionWithDepthMapsForMobileAugmentedReality_UIST2020.pdf><img src=assets/img/DepthLab1.jpg alt="Download DepthLab Paper in pdf" class=linkimg></a> </div> <div class=page> <a href=assets/Du_DepthLab-Real-Time3DInteractionWithDepthMapsForMobileAugmentedReality_UIST2020.pdf><img src=assets/img/DepthLab2.jpg alt="Download DepthLab Paper in pdf" class=linkimg></a> </div> <div class=page> <a href=assets/Du_DepthLab-Real-Time3DInteractionWithDepthMapsForMobileAugmentedReality_UIST2020.pdf><img src=assets/img/DepthLab3.jpg alt="Download DepthLab Paper in pdf" class=linkimg></a> </div> <div class=page> <a href=assets/Du_DepthLab-Real-Time3DInteractionWithDepthMapsForMobileAugmentedReality_UIST2020.pdf><img src=assets/img/DepthLab4.jpg alt="Download DepthLab Paper in pdf" class=linkimg></a> </div> <p class=pt-15> Click to <a href=assets/Du_DepthLab-Real-Time3DInteractionWithDepthMapsForMobileAugmentedReality_UIST2020.pdf class=content-link>download</a> a PDF of the paper. </p> </div> <div class=section> <h5>Abstract</h5> <p> <span class=dropcap>M</span>obile devices with passive depth sensing capabilities are ubiquitous, and recently active depth sensors have become available on some tablets and AR/VR devices. Although real-time depth data is accessible, its rich value to mainstream AR applications has been sorely under-explored. Adoption of depth-based UX has been impeded by the complexity of performing even simple operations with raw depth data, such as detecting intersections or constructing meshes. In this paper, we introduce DepthLab, a software library that encapsulates a variety of depth-based UI/UX paradigms, including geometry-aware rendering (occlusion, shadows), surface interaction behaviors (physics-based collisions, avatar path planning), and visual effects (relighting, 3D-anchored focus and aperture effects). We break down the usage of depth into localized depth, surface depth, and dense depth, and describe our real-time algorithms for interaction and rendering tasks. We present the design process, system, and components of DepthLab to streamline and centralize the development of interactive depth features. We have open-sourced our software at <a href=https://github.com/googlesamples/arcore-depth-lab target=_blank>https://github.com/googlesamples/arcore-depth-lab</a> to external developers, conducted performance evaluation, and discussed how DepthLab can accelerate the workflow of mobile AR designers and developers. With DepthLab we aim to help mobile developers to effortlessly integrate depth into their AR experiences and amplify the expression of their creative vision. </p> </div> </div> <div class=content> <div class=section> <h5>GitHub</h5> <p> Depth Lab is available as <a href=https://github.com/googlesamples/arcore-depth-lab target=_blank> <b>open-source code on GitHub</b></a>. Depth Lab is a set of ARCore Depth API samples that provides assets using depth for advanced geometry-aware features in AR interaction and rendering. </p> <iframe src="https://ghbtns.com/github-btn.html?user=googlesamples&repo=arcore-depth-lab&type=star&count=true&size=large" frameborder=0 scrolling=0 width=170 height=30 title=GitHub></iframe> </div> <div class=section> <h5>Google Play Store</h5> Download the pre-built ARCore Depth Lab app on Google Play Store today. <p> <a class=imglink href="https://play.google.com/store/apps/details?id=com.google.ar.unity.arcore_depth_lab"> <img alt="Get ARCore Depth Lab on Google Play" height=50px src=https://camo.githubusercontent.com/f70a0ab979eaba7ed74873bc9dfcd3fa47815a5f/68747470733a2f2f706c61792e676f6f676c652e636f6d2f696e746c2f656e5f75732f6261646765732f696d616765732f617070732f656e2d706c61792d62616467652d626f726465722e706e67 data-canonical-src=https://play.google.com/intl/en_us/badges/images/apps/en-play-badge-border.png style=max-width:100%; class=linkimg> </a> </p> </div> <div class=section> <h5>Media Coverage</h5> <div class=row> <div class=col2> <iframe width=493 height=277 src=https://www.youtube.com/embed/cLQJ864LNWI frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <br> <div class=center> 46s teaser of ARCore Depth API. </div> </div> <div class=col2> <iframe width=493 height=277 src=https://www.youtube.com/embed/VOVhCTb-1io frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <br> <div class=center> 3min deep dive of ARCore Depth API. </div> </div> </div> <ul> <li> <a href=https://developers.googleblog.com/2020/06/a-new-wave-of-ar-realism-with-arcore-depth-api.html target=_blank>A New Wave of AR Realism with the ARCore Depth API.</a> Google Developers. June 25, 2020. </li> <li> <a href=https://www.engadget.com/google-makes-its-a-rcentric-depth-api-available-to-all-developers-130037924.html target=_blank>Google Makes Its AR-Centric Depth API Available to All Developers.</a> Engadget. June 25, 2020. </li> <li> <a href="https://www.youtube.com/watch?v=q3Jd98xyBAA" target=_blank>AR Realism with the ARCore Depth API (Video).</a> Google Developers. June 25, 2020. </li> <li> <a href=https://www.androidpolice.com/2020/06/25/arcore-depth-api/ target=_blank>ARCore’s new Depth API is out of beta, bringing the next generation of hide-and-seek to phones.</a> Android Police. June 25, 2020. </li> <li> <a href=https://www.zdnet.com/article/google-is-improving-its-augmented-reality-tool-so-virtual-cats-can-hide-behind-your-sofa/ target=_blank>Google is improving its augmented reality tool so virtual cats can hide behind your sofa.</a> ZDNet. December 10, 2019. </li> <li> <a href=https://www.xda-developers.com/google-arcore-depth-api-create-depth-maps-using-single-camera/ target=_blank>ARCore’s Depth API helps create depth maps using a single camera.</a> XDA Developers. December 10, 2019. </li> <li> <a href=https://www.cnet.com/news/googles-new-phone-ar-update-can-hide-virtual-things-in-the-real-world/ target=_blank>Google's New Phone AR Update Can Hide Virtual Things in the Real World.</a> CNET. December 9, 2019. </li> <li> <a href=https://www.theverge.com/2019/12/9/20999646/google-arcore-augmented-reality-updates-occlusion-physics-depth target=_blank>Google Shows off Stunning New AR Features Coming to Web and Mobile Apps Soon.</a> The Verge. December 9, 2019. </li> <li> <a href=https://venturebeat.com/2019/12/09/googles-arcore-depth-api-enables-ar-depth-maps-and-occlusion-with-one-camera/ target=_blank>Google’s ARCore Depth API Enables AR Depth Maps and Occlusion with One Camera.</a> VentureBeat. December 9, 2019. </li> <li> <a href=https://uploadvr.com/arcore-depth-api/ target=_blank>Google’s ARCore Is Getting Full Occlusion For More Real AR.</a> UploadVR. December 9, 2019. </li> <li> <a href=https://www.roadtovr.com/google-depth-api-arcore-augmented-reality/ target=_blank>Google ARCore Depth API Now Available, Letting Devs Make AR More Realistic.</a> RoadToVR. December 9, 2019. </li> <li> <a href=https://vrscout.com/news/google-arcore-depth-api-release/ target=_blank>ARCore Depth API Takes Android AR Experiences To A Whole New Level.</a> VRScout. December 9, 2019. </li> <li> <a href=https://mobile-ar.reality.news/news/google-update-adds-real-world-occlusion-arcore-with-depth-api-0216126/ target=_blank>Google Update Adds Real-World Occlusion to ARCore with Depth API.</a> Next Reality. December 9, 2019. </li> <li> <a href=https://9to5google.com/2019/12/09/google-arcore-depth/ target=_blank>ARCore phones can now detect depth with a single camera.</a> 9To5Google. December 9, 2019. </li> <li> <a href=https://www.androidauthority.com/arcore-depth-api-1064324/ target=_blank>ARCore Depth API: How it will fundamentally transform your AR experiences.</a> Android Authority. December 9, 2019. </li> <li> <a href=https://www.androidauthority.com/arcore-depth-api-1064324/ target=_blank>ARCore Depth API lets you hide cats behind sofas even with one camera.</a> SlashGear. December 9, 2019. </li> <li> <a href=https://hothardware.com/news/google-arcore-update target=_blank>Google's Latest ARCore API Needs Just One Camera For Depth Detection.</a> HotHardware. December 9, 2019. </li> <li> <a href="https://www.youtube.com/watch?v=1q0-jdknbTs" target=_blank>Get Ready for the ARCore Depth API (Video).</a> Google AR & VR. December 9, 2019. </li> <li> <a href=https://developers.googleblog.com/2019/12/blending-realities-with-arcore-depth-api.html target=_blank>Blending Realities with the ARCore Depth API.</a> Google Developers. December 9, 2019. </li> </ul> </div> <div class=section> <h5>Presentation and Talks</h5> <div class=row> <div class=col2> <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vSD30LxJMsR_Zlb_AYznkFZiO7HekbmbdwT8oO1oVk_tv980F0JzMNlksUovV_AEAPsEz_KTLzs2Y9A/embed?start=false&loop=false&delayms=3000" frameborder=0 width=491 height=307 allowfullscreen=true mozallowfullscreen=true webkitallowfullscreen=true></iframe> </div> <div class=col2> <iframe width=493 height=277 src=https://www.youtube.com/embed/MhDTNzaqlqY frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <br> <div class=center> 5-min UIST talk. Click <a href=https://youtu.be/XhqbbQx0R0g alt="15-min version of the talk">here</a> to watch the 15-min version. </div> </div> </div> </div> <div class=section> <h5>Supplementary Material</h5> We list all ideas from our brainstorming sessions and discuss their depth representation requirements, use cases, and whether each is implemented in DepthLab in <a href=assets/Du_DepthLab-Real-Time3DInteractionWithDepthMapsForMobileAugmentedReality_UIST2020_supp.pdf target=_blank alt="Supplementary material">this 4-page PDF</a>. We further present more results in <a href=assets/Du_ExperiencingReal-Time3DInteractionWithDepthMapsForMobileAugmentedRealityInDepthLab_UIST2020.pdf target=_blank alt="demo paper">this 3-page PDF for UIST demo</a>. <ul> <li> <a href=https://github.com/googlesamples/arcore-depth-lab target=_blank> ARCore DepthLab GitHub (Unity) </a> </li> <li> <a href="https://developers.google.com/codelabs/arcore-depth?hl=en#0" target=_blank> ARCore Depth Codelab (with Android Studio)</a> </li> </ul> </div> <div class=section> <h5 style="text-transform: none;">BibTeX</h5> <!-- prettier-ignore --> <textarea id=bibtex-text class="ta-cite bibtex" autocomplete=off spellcheck=false>@inproceedings{Du2020DepthLab,
  title = {{DepthLab: Real-Time 3D Interaction With Depth Maps for Mobile Augmented Reality}},
  author = {Du, Ruofei and Turner, Eric and Dzitsiuk, Maksym and Prasso, Luca and Duarte, Ivo and Dourgarian, Jason and Afonso, Joao and Pascoal, Jose and Gladstone, Josh and Cruces, Nuno and Izadi, Shahram and Kowdle, Adarsh and Tsotsos, Konstantine and Kim, David},
  booktitle = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
  year = {2020},
  publisher = {ACM},
  numpages = {15},
  series = {UIST},
  doi = {10.1145/3379337.3415881}
}</textarea> </div> <div class=section> <h5 style="text-transform: none;">ACM Citation Format</h5> <!-- prettier-ignore --> <textarea id=bibtex-text class="ta-cite bibacm" autocomplete=off spellcheck=false>Ruofei Du, Eric Turner, Maksym Dzitsiuk, Luca Prasso, Ivo Duarte, Jason Dourgarian, Joao Afonso, Jose Pascoal, Josh Gladstone, Nuno Cruces, Shahram Izadi, Adarsh Kowdle, Konstantine Tsotsos, and David Kim. 2020. DepthLab: Real-Time 3D Interaction With Depth Maps for Mobile Augmented Reality. Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, pp. 15. DOI: 10.1145/3379337.3415881.</textarea> </div> </div> <div class=footer> <div class=footer-decoration> <div class=footer-decoration-col style="background-color: #aecbfa;"></div> <div class=footer-decoration-col style="background-color: #f6aea9;"></div> <div class=footer-decoration-col style="background-color: #fde293;"></div> <div class=footer-decoration-col style="background-color: #a8dab5;"></div> </div> <div class=footer-content> <div class=footer-links-row> <div class=footer-links-left> <h6>Related Work</h6> <ul class=footer-links> <li> <a href=https://research.google/pubs/pub48288 target=_blank>Depth From Motion for Smartphone AR (SIGGRAPH Asia 2018)</a> </li> </ul> </div> <div class=footer-links-right> <a href=https://ai.google/ class=imglink><img src=https://augmentedperception.github.io/deepview/thumbs/google.png class="logos linkimg"></a> </div> </div> </div> </div> </div> <script src=assets/js/main.js></script> </body> </html> 